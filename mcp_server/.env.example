# Graphiti MCP Server Environment Configuration
# Copy this file to .env and configure your settings

# =============================================================================
# Neo4j Database Configuration
# =============================================================================
# These settings are used to connect to your Neo4j database
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=demodemo

# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Choose your LLM provider: openai, openrouter, or azure
LLM_PROVIDER=openrouter

# Model Configuration
MODEL_NAME=google/gemini-2.5-flash-preview-05-20
SMALL_MODEL_NAME=openai/gpt-4.1-nano
LLM_TEMPERATURE=0.1

OPENROUTER_API_KEY=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

# =============================================================================
# OpenAI Configuration
# =============================================================================
# Required when LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-your-openai-api-key-here

# Optional: Custom OpenAI-compatible endpoint
# OPENAI_BASE_URL=https://api.openai.com/v1

# =============================================================================
# OpenRouter Configuration (Cost-Effective Alternative)
# =============================================================================
# Required when LLM_PROVIDER=openrouter
# Get your API key from: https://openrouter.ai
# OPENROUTER_API_KEY=sk-or-v1-your-openrouter-key-here

# Recommended OpenRouter Models:
# Budget Options (Free Tier):
# MODEL_NAME=meta-llama/llama-3.1-8b-instruct:free
# MODEL_NAME=microsoft/phi-3-mini-128k-instruct:free
# MODEL_NAME=google/gemma-2-9b-it:free

# Balanced Performance/Cost:
# MODEL_NAME=meta-llama/llama-3.1-70b-instruct
# MODEL_NAME=anthropic/claude-3-haiku
# MODEL_NAME=google/gemini-pro-1.5

# Premium Options:
# MODEL_NAME=anthropic/claude-3-opus
# MODEL_NAME=openai/gpt-4-turbo

# =============================================================================
# Azure OpenAI Configuration
# =============================================================================
# Required when LLM_PROVIDER=azure
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_OPENAI_API_VERSION=2024-10-21
# AZURE_OPENAI_DEPLOYMENT_NAME=your-gpt-deployment-name
# AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=your-embedding-deployment-name
# AZURE_OPENAI_EMBEDDING_API_VERSION=2023-05-15
# AZURE_OPENAI_USE_MANAGED_IDENTITY=false

# =============================================================================
# Embedding Configuration
# =============================================================================
# Embedding model configuration
EMBEDDER_MODEL_NAME=text-embedding-3-small

# Optional: Use different provider for embeddings
# EMBEDDER_PROVIDER=openai
# EMBEDDER_BASE_URL=https://api.openai.com/v1

# For mixed setups (e.g., OpenRouter for LLM, OpenAI for embeddings):
# LLM_PROVIDER=openrouter
# OPENROUTER_API_KEY=sk-or-v1-your-key-here
# EMBEDDER_PROVIDER=openai
# OPENAI_API_KEY=sk-your-openai-key-here

# =============================================================================
# Optional Configuration
# =============================================================================
# Group ID for namespacing graph data (useful for multi-project setups)
# GROUP_ID=my_project

# Docker-specific PATH configuration
# PATH=/root/.local/bin:${PATH}

# =============================================================================
# Neo4j Memory Settings (Docker Compose)
# =============================================================================
# Optional: Memory settings for Neo4j container
# NEO4J_server_memory_heap_initial__size=512m
# NEO4J_server_memory_heap_max__size=1G
# NEO4J_server_memory_pagecache_size=512m

# =============================================================================
# Example Configurations
# =============================================================================

# Example 1: Pure OpenAI Setup
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-your-openai-key
# MODEL_NAME=gpt-4o-mini

# Example 2: Pure OpenRouter Setup (Cost-Effective)
# LLM_PROVIDER=openrouter
# OPENROUTER_API_KEY=sk-or-v1-your-key
# MODEL_NAME=meta-llama/llama-3.1-70b-instruct
# SMALL_MODEL_NAME=meta-llama/llama-3.1-8b-instruct

# Example 3: Mixed Setup (OpenRouter for LLM, OpenAI for Embeddings)
# LLM_PROVIDER=openrouter
# OPENROUTER_API_KEY=sk-or-v1-your-key
# MODEL_NAME=meta-llama/llama-3.1-70b-instruct
# EMBEDDER_PROVIDER=openai
# OPENAI_API_KEY=sk-your-openai-key
# EMBEDDER_MODEL_NAME=text-embedding-3-small

# Example 4: Budget Setup with Free Models
# LLM_PROVIDER=openrouter
# OPENROUTER_API_KEY=sk-or-v1-your-key
# MODEL_NAME=meta-llama/llama-3.1-8b-instruct:free
# SMALL_MODEL_NAME=meta-llama/llama-3.1-8b-instruct:free 
